{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name:林淞祐\n",
    "\n",
    "Student ID:111061562\n",
    "\n",
    "GitHub ID:ansonlin3578\n",
    "\n",
    "Kaggle name: Sung-Yu Lin\n",
    "\n",
    "Kaggle private scoreboard snapshot:\n",
    "\n",
    "[Snapshot](img/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home** exercises in the DM2023-Lab2-master. You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/t/09b1d0f3f8584d06848252277cb535f2) regarding Emotion Recognition on Twitter by this link https://www.kaggle.com/t/09b1d0f3f8584d06848252277cb535f2. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (60-x)/6 + 20 points, where x is your ranking in the leaderboard (ie. If you rank 3rd your score will be (60-3)/6 + 20 = 29.5% out of 30%)   \n",
    "    Submit your last submission __BEFORE the deadline (Dec. 27th 11:59 pm, Wednesday)_. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developping the model for the competition (You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Dec. 31th 11:59 pm, Sunday)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third PART\n",
    "### [Report](report/DM_Lab2_projectReport.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First PART\n",
    "### Here, i only paste the exercise part , if you want run it and look up the plot, you should go back to the [DM2023-Lab2-Homework.ipynb](../DM2023-Lab2-Master.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 1 (Take home): **  \n",
    "Plot word frequency for Top 30 words in both train and test dataset. (Hint: refer to DM lab 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import plotly.express as px\n",
    "\n",
    "def text_freq(data):\n",
    "    count_vect = CountVectorizer()\n",
    "    X_counts = count_vect.fit_transform(data.text) \n",
    "    \n",
    "    term_frequencies = []\n",
    "    for j in range(0,X_counts.shape[1]):\n",
    "        term_frequencies.append(sum(X_counts[:,j].toarray()))\n",
    "        \n",
    "    sort_idx, sort_count = [], []\n",
    "    sort_freq = sorted(enumerate(term_frequencies), key=lambda i: i[1], reverse=True)\n",
    "    for idx, count in sort_freq:\n",
    "        sort_idx.append(idx)\n",
    "        sort_count.append(count[0])\n",
    "    sort_term = count_vect.get_feature_names_out()[sort_idx]\n",
    "    \n",
    "    d = {'term_name': sort_term[:30], 'count': sort_count[:30]}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    \n",
    "    fig = px.bar(df, x='term_name', y='count')\n",
    "    fig.show()\n",
    "for data in [train_df, test_df]:\n",
    "    text_freq(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 2 (Take home): **  \n",
    "Generate an embedding using the TF-IDF vectorizer instead of th BOW one with 1000 features and show the feature names for features [100:110]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(train_df.text)\n",
    "\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "feature_names[100:110]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 3 (Take home): **  \n",
    "Can you interpret the results above? What do they mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer here\n",
    "In the confusion matrix, the elements on the diagonal represent the correct predictions of the model, with the main diagonal containing True Positives (TP) and True Negatives (TN). Therefore, a higher score on the diagonal indicates that the model's predictions for both positive and negative classes are more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 4 (Take home): **  \n",
    "Build a model using a ```Naive Bayes``` model and train it. What are the testing results? \n",
    "\n",
    "*Reference*: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "naive_bayes_model = MultinomialNB()\n",
    "naive_bayes_model.fit(X_train, y_train)\n",
    "y_pred = naive_bayes_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 5 (Take home): **  \n",
    "\n",
    "How do the results from the Naive Bayes model and the Decision Tree model compare? How do you interpret these differences? Use the theoretical background covered in class to try and explain these differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer here\n",
    "The Naive Bayes Performs Better:\n",
    "The dataset may exhibit a stronger adherence to the independence assumption.\n",
    "The data might have a high-dimensional and sparse nature, where Naive Bayes excels, such as in text classification.\n",
    "Computationally efficient, especially with large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 6 (Take home): **  \n",
    "\n",
    "Plot the Training and Validation Accuracy and Loss (different plots), just like the images below.(Note: the pictures below are an example from a different model). How to interpret the graphs you got? How are they related to the concept of overfitting/underfitting covered in class?\n",
    "<table><tr>\n",
    "    <td><img src=\"../pics/pic3.png\" style=\"width: 300px;\"/> </td>\n",
    "    <td><img src=\"../pics/pic4.png\" style=\"width: 300px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "\n",
    "train_acc = training_log['accuracy']\n",
    "train_loss = training_log['loss']\n",
    "val_acc = training_log['val_accuracy']\n",
    "val_loss = training_log['val_loss']\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "train_acc.plot(marker='o')\n",
    "val_acc.plot(marker='o', color='r')\n",
    "plt.title('Accuracy Curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Plotting loss curve\n",
    "plt.subplot(1, 2, 2)\n",
    "train_loss.plot(marker='o')\n",
    "val_loss.plot(marker='o', color='r')\n",
    "plt.title('Loss Curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 7 (Take home): **  \n",
    "\n",
    "Now, we have the word vectors, but our input data is a sequence of words (or say sentence). \n",
    "How can we utilize these \"word\" vectors to represent the sentence data and train our model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer here\n",
    "1.Calculate the average of all word vectors in the sentence.<br>\n",
    "2.Assign weights to word vectors based on importance (e.g., TF-IDF scores) and calculate the weighted average.<br>\n",
    "3.Use algorithms like Doc2Vec, which extends Word2Vec to learn document-level embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 8 (Take home): **  \n",
    "\n",
    "Generate a t-SNE visualization to show the 15 words most related to the words \"angry\", \"happy\", \"sad\", \"fear\" (60 words total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "word_list = [\"angry\", \"happy\", \"sad\", \"fear\"]\n",
    "\n",
    "topn = 15\n",
    "angry_words = ['angry'] + [word_ for word_, sim_ in w2v_google_model.most_similar('angry', topn=topn)]\n",
    "happy_words = ['happy'] + [word_ for word_, sim_ in w2v_google_model.most_similar('happy', topn=topn)]        \n",
    "sad_words = ['sad'] + [word_ for word_, sim_ in w2v_google_model.most_similar('sad', topn=topn)]        \n",
    "fear_words = ['fear'] + [word_ for word_, sim_ in w2v_google_model.most_similar('fear', topn=topn)]        \n",
    "\n",
    "print('angry_words: ', angry_words)\n",
    "print('happy_words: ', happy_words)\n",
    "print('sad_words: ', sad_words)\n",
    "print('fear_words: ', fear_words)\n",
    "\n",
    "target_words = angry_words + happy_words + sad_words + fear_words\n",
    "print('\\ncolor list:')\n",
    "cn = topn + 1\n",
    "color = ['b'] * cn + ['g'] * cn + ['r'] * cn + ['y'] * cn\n",
    "print(color)\n",
    "\n",
    "model = w2v_google_model\n",
    "\n",
    "## prepare training word vectors\n",
    "size = 200\n",
    "target_size = len(target_words)\n",
    "all_word = list(model.index_to_key)\n",
    "word_train = target_words + all_word[:size]\n",
    "X_train = model[word_train]\n",
    "\n",
    "## t-SNE model\n",
    "tsne = TSNE(n_components=2, metric='cosine', random_state=28)\n",
    "\n",
    "## training\n",
    "X_tsne = tsne.fit_transform(X_train)\n",
    "\n",
    "## plot the result\n",
    "plt.figure(figsize=(7.5, 7.5), dpi=115)\n",
    "plt.scatter(X_tsne[:target_size, 0], X_tsne[:target_size, 1], c=color)\n",
    "for label, x, y in zip(target_words, X_tsne[:target_size, 0], X_tsne[:target_size, 1]):\n",
    "    plt.annotate(label, xy=(x,y), xytext=(0,0),  textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
